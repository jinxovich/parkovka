import cv2
from ultralytics import YOLO
import time
import torch
import os

VIDEO_SOURCE = 'test1.mp4'  
OUTPUT_FILE = 'final_result.mp4'

MODEL_SIGNS = 'models/traffic_signs_v1.pt'  
MODEL_ROAD = 'models/road_surface_v1.pt'    

# –†–∞–∑–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á
CONF_SIGNS = 0.50  
CONF_ROAD = 0.25   

def main():
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–µ–π
    if not os.path.exists(MODEL_ROAD):
        print(f"‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª {MODEL_ROAD}")
        print("–°–∫–æ–ø–∏—Ä—É–π runs/detect/road_surface_v1/weights/best.pt –≤ –ø–∞–ø–∫—É models/ –∏ –Ω–∞–∑–æ–≤–∏ road_surface_v1.pt")
        return

    print(f"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –Ω–∞ {torch.cuda.get_device_name(0)}...")
    
    # –ì—Ä—É–∑–∏–º –º–æ–¥–µ–ª–∏
    try:
        model_signs = YOLO(MODEL_SIGNS)
        model_road = YOLO(MODEL_ROAD)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return

    cap = cv2.VideoCapture(VIDEO_SOURCE)
    if not cap.isOpened():
        print("‚ùå –ù–µ –º–æ–≥—É –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ!")
        return

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(OUTPUT_FILE, fourcc, fps, (width, height))

    print(f"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {width}x{height} @ {fps}FPS")
    
    frame_count = 0
    start_time = time.time()

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count += 1

        # --- 1. –î–µ—Ç–µ–∫—Ü–∏—è –î–û–†–û–ì–ò (–Ø–º—ã, –õ—é–∫–∏, –õ–µ–∂–∞—á–∏–µ) ---
        #  conf –ø–æ–Ω–∏–∂–µ, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å —Ç—Ä–µ—â–∏–Ω—ã
        results_road = model_road.predict(frame, conf=CONF_ROAD, verbose=False, device=0)
        
        # --- 2. –î–µ—Ç–µ–∫—Ü–∏—è –ó–ù–ê–ö–û–í ---
        #  conf –ø–æ–≤—ã—à–µ, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å –º—É—Å–æ—Ä
        results_signs = model_signs.predict(frame, conf=CONF_SIGNS, verbose=False, device=0)

        # --- –û–¢–†–ò–°–û–í–ö–ê (–°–ª–æ—è–º–∏) ---
        
        # –°–ª–æ–π 1: –†–∏—Å—É–µ–º —è–º—ã –Ω–∞ —á–∏—Å—Ç–æ–º –∫–∞–¥—Ä–µ
        # plot() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç numpy –º–∞—Å—Å–∏–≤ (–∫–∞—Ä—Ç–∏–Ω–∫—É)
        annotated_frame = results_road[0].plot(line_width=2) 
        
        # –°–ª–æ–π 2: –†–∏—Å—É–µ–º –∑–Ω–∞–∫–∏ –ü–û–í–ï–†–• —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å —è–º–∞–º–∏
        # –ê—Ä–≥—É–º–µ–Ω—Ç img=annotated_frame –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–∏—Å–æ–≤–∞—Ç—å –Ω–∞ —É–∂–µ –≥–æ—Ç–æ–≤–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ
        annotated_frame = results_signs[0].plot(img=annotated_frame, line_width=2)

        # –ü–æ–∫–∞–∑
        cv2.imshow('Parkovka AI: Road + Signs', annotated_frame)
        out.write(annotated_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    end_time = time.time()
    total_time = end_time - start_time
    
    print("-" * 30)
    print(f"–ì–æ—Ç–æ–≤–æ!")
    print(f"–ö–∞–¥—Ä–æ–≤: {frame_count}")
    print(f"–í—Ä–µ–º—è: {total_time:.1f} —Å–µ–∫")
    print(f"–°—Ä–µ–¥–Ω–∏–π FPS: {frame_count / total_time:.1f}")
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {OUTPUT_FILE}")

    cap.release()
    out.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()